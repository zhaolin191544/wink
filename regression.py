# åŸºäºå¼¹æ€§å›¾çš„Eå€¼å›å½’é¢„æµ‹
# written by Lin
# æ–¹æ³•ï¼šç›´æ¥å›å½’ (å›¾åƒ -> Eå€¼)
# æ¨¡å‹ï¼šResNet18 (é¢„è®­ç»ƒ)

# æ•´ä½“ä»£ç é€»è¾‘ï¼š
# [JSONæ–‡ä»¶ & å›¾åƒæ–‡ä»¶]
#          |
#          v
# [RegressionDataset]
#   |__ __init__(json_path, root_dir, dataset_type, transform)
#   |__ __len__()
#   |__ __getitem__(idx) --> (image, e_value_tensor)
#          |
#          v
# [DataLoader] --> (images, labels) æ‰¹æ¬¡æ•°æ®
#          |
#          v
# [ä¸»æ‰§è¡Œæµç¨‹]
#   |__ å®šä¹‰å›¾åƒå˜æ¢ (ç”±ResNet18é¢„è®­ç»ƒæƒé‡æä¾›)
#   |__ åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯• DataLoader
#   |__ åˆå§‹åŒ–å›å½’æ¨¡å‹
#   |      |
#   |      v
#   |   [create_regression_model()]
#   |      |__ åŠ è½½é¢„è®­ç»ƒçš„ ResNet18
#   |      |__ æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚ï¼Œä½¿å…¶è¾“å‡ºä¸º1 (Eå€¼)
#   |      |
#   |      v
#   |__ åˆå§‹åŒ–æŸå¤±å‡½æ•° (MSELoss) & ä¼˜åŒ–å™¨ (Adam)
#   |__ å¾ªç¯: NUM_EPOCHS
#   |      |
#   |      v
#   |   [train_fn(model, train_loader, optimizer, loss_fn)] --> è®­ç»ƒä¸€ä¸ªå‘¨æœŸçš„æ¨¡å‹
#   |      |__ éå†è®­ç»ƒæ‰¹æ¬¡
#   |      |__ æ¨¡å‹é¢„æµ‹: predictions = model(images)
#   |      |__ è®¡ç®—æŸå¤±: loss = loss_fn(predictions, labels)
#   |      |__ åå‘ä¼ æ’­ & æ›´æ–°ä¼˜åŒ–å™¨
#   |      |
#   |      v
#   |   [evaluate_fn(model, val_loader)] --> åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
#   |      |__ éå†éªŒè¯æ‰¹æ¬¡
#   |      |__ æ”¶é›†æ‰€æœ‰çœŸå®æ ‡ç­¾å’Œæ¨¡å‹é¢„æµ‹å€¼
#   |      |__ è®¡ç®—æ•´ä½“çš„ MAE å’Œ RMSE
#   |      |__ æ£€æŸ¥å¹¶ä¿å­˜æœ€ä½³æ¨¡å‹ (åŸºäºæœ€ä½çš„ val_mae)
#   |      |
#   |      v
#   |   [è®­ç»ƒç»“æŸ]
#   |      |
#   |      v
#   |   [æœ€ç»ˆæµ‹è¯•]
#   |      |__ åŠ è½½æœ€ä½³å›å½’æ¨¡å‹ (best_regression_model.pth)
#   |      |__ åœ¨æµ‹è¯•é›†ä¸Šè°ƒç”¨ evaluate_fn
#   |      |__ æ‰“å°æœ€ç»ˆçš„ MAE å’Œ RMSE è¯„ä¼°ç»“æœ

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from PIL import Image
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error

#å‚æ•°
DEVICE = torch.device("cuda")
LEARNING_RATE = 1e-4
BATCH_SIZE = 128
NUM_EPOCHS = 50

# æ•°æ®è·¯å¾„
JSON_FILE_PATH = "./dataset_E.json"
IMAGE_ROOT_DIR = "./images/"

# æ•°æ®é›†åŠ è½½å™¨
class RegressionDataset(Dataset):
    def __init__(self, json_path, root_dir, dataset_type="train", transform=None):
        print(f"ä»{json_path}åŠ è½½{dataset_type}æ•°æ®...")
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        if dataset_type not in data:
            raise ValueError(f"é”™è¯¯ï¼šJSONæ–‡ä»¶ä¸­æœªæ‰¾åˆ° '{dataset_type}' é”®ã€‚")

        self.image_data_list = list(data[dataset_type].items())
        self.root_dir = root_dir
        self.transform = transform
        print(f"ä»{dataset_type}é›†è¯»å–åˆ°{len(self.image_data_list)}å¼ å›¾ç‰‡")

    def __len__(self):
        return len(self.image_data_list)

    def __getitem__(self, idx):
        img_relative_path, data_dict = self.image_data_list[idx]
        e_value = float(data_dict["E"])
        img_full_path = os.path.join(self.root_dir, img_relative_path)
        image = Image.open(img_full_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        # å›å½’ä»»åŠ¡çš„æ ‡ç­¾æ˜¯ä¸€ä¸ªæ•°å€¼
        return image, torch.tensor(e_value, dtype=torch.float32)

# æ¨¡å‹å®šä¹‰
def create_regression_model():
    # åŠ è½½ResNet18
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 1)
    
    return model.to(DEVICE)

# è®­ç»ƒä¸è¯„ä¼°å‡½æ•°
def train_fn(model, loader, optimizer, loss_fn):
    model.train()
    total_loss = 0
    for images, labels in loader:
        images = images.to(DEVICE)
        labels = labels.to(DEVICE)
        
        # æ¨¡å‹é¢„æµ‹
        predictions = model(images)
        
        # è®¡ç®—æŸå¤±
        loss = loss_fn(predictions.squeeze(1), labels)
        total_loss += loss.item()
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
    avg_loss = total_loss / len(loader)
    print(f"è®­ç»ƒå¹³å‡æŸå¤±: {avg_loss:.4f}")

def evaluate_fn(model, loader):
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(DEVICE)
            predictions = model(images)
            all_preds.extend(predictions.squeeze(1).cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    mae = mean_absolute_error(all_labels, all_preds)
    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))
    
    return mae, rmse

# ä¸»æ‰§è¡Œ
if __name__ == "__main__":
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    # Refï¼šğŸ‘‡
    # ResNeté¢„è®­ç»ƒæ¨¡å‹è¦æ±‚çš„å›¾åƒå˜æ¢
    # ä½¿ç”¨å…¶æ¨èçš„å‡å€¼å’Œæ ‡å‡†å·®
    weights = models.ResNet18_Weights.DEFAULT
    transform = weights.transforms()
    print("ç”±é¢„è®­ç»ƒæ¨¡å‹æä¾›çš„å›¾åƒå˜æ¢æµç¨‹:")
    print(transform)

    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    train_dataset = RegressionDataset(JSON_FILE_PATH, IMAGE_ROOT_DIR, 'train', transform)
    val_dataset = RegressionDataset(JSON_FILE_PATH, IMAGE_ROOT_DIR, 'val', transform)
    test_dataset = RegressionDataset(JSON_FILE_PATH, IMAGE_ROOT_DIR, 'test', transform)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    model = create_regression_model()
    loss_fn = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # floop train
    best_val_mae = float('inf')
    best_epoch = 0

    for epoch in range(1, NUM_EPOCHS + 1):
        print(f"\n--- Epoch {epoch}/{NUM_EPOCHS} ---")
        train_fn(model, train_loader, optimizer, loss_fn)
        
        # åœ¨valä¸Šè¯„ä¼°
        val_mae, val_rmse = evaluate_fn(model, val_loader)
        print(f"--- valè¯„ä¼° (Epoch {epoch}) ---")
        print(f"MAE: {val_mae:.4f}")
        print(f"RMSE: {val_rmse:.4f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_mae < best_val_mae:
            best_val_mae = val_mae
            best_epoch = epoch
            torch.save(model.state_dict(), "best_regression_model.pth")
            print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (Epoch {epoch})ï¼Œval MAE: {best_val_mae:.4f}")

    print("\n--- è®­ç»ƒå®Œæˆ ---")
    print(f"æœ€ä½³æ¨¡å‹å‡ºç°åœ¨ Epoch {best_epoch}ï¼Œå…¶åœ¨valä¸Šçš„MAEä¸º {best_val_mae:.4f}")

    # åŠ è½½æœ€ä½³æ¨¡å‹
    # åœ¨testä¸Šè¿›è¡Œè¯„ä¼°
    print("\nåŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
    best_model = create_regression_model()
    best_model.load_state_dict(torch.load("best_regression_model.pth"))
    
    test_mae, test_rmse = evaluate_fn(best_model, test_loader)
    print("\næœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ç»“æœ")
    print(f"MAE: {test_mae:.4f}")
    print(f"RMSE: {test_rmse:.4f}")